# -*- coding: utf-8 -*-
"""House price prediction model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qd0we3Q2Hrfyp1bYTs4C6xIqwId6JZIh

Importing Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
# %matplotlib inline

"""Load and Explore Data"""

# Load the dataset
data = pd.read_csv("housing.csv")

# Display dataset information and first few rows
print("Dataset Info:")
data.info()
print("\nFirst few rows:")
display(data.head())

# Display the entire dataset (as in original code)
display(data)

# Visualize distribution of all numerical features (as in original code)
data.hist(figsize=(15, 8))
plt.tight_layout()
plt.show()

# Visualize distribution of the target variable
plt.figure(figsize=(10, 6))
sns.histplot(data['median_house_value'], bins=50, kde=True)
plt.title('Distribution of Median House Value')
plt.xlabel('Median House Value')
plt.ylabel('Frequency')
plt.show()

"""Data Preprocessing

Handle Missing Values
"""

# Check for missing values
print("Missing Values:")
print(data.isnull().sum())

# Drop rows with missing values (as in original code)
data.dropna(inplace=True)

print(data.isnull().sum())

"""Encode Categorical Variables"""

# One-hot encode ocean_proximity (as in original code)
data = data.join(pd.get_dummies(data['ocean_proximity'])).drop(['ocean_proximity'], axis=1)

# Display the dataset after encoding
display(data)

"""Feature Engineering"""

# Log-transform skewed numerical features (as in original code)
data['total_rooms'] = np.log(data['total_rooms'] + 1)
data['total_bedrooms'] = np.log(data['total_bedrooms'] + 1)
data['population'] = np.log(data['population'] + 1)
data['households'] = np.log(data['households'] + 1)

# Visualize distributions after log transformation (as in original code)
data.hist(figsize=(15, 8))
plt.tight_layout()
plt.show()

# Create new features (as in original code)
data['bedroom_ratio'] = data['total_bedrooms'] / data['total_rooms']
data['household_rooms'] = data['total_rooms'] / data['households']

# Visualize correlation matrix (as in original code)
plt.figure(figsize=(15, 8))
sns.heatmap(data.corr(), annot=True, cmap='YlGnBu', fmt='.2f')
plt.title('Correlation Matrix of Features')
plt.show()

# Scatter plot of geographical features (as in original code)
plt.figure(figsize=(15, 8))
sns.scatterplot(data=data, x='latitude', y='longitude', hue='median_house_value', palette='coolwarm', alpha=0.6)
plt.title('Geographical Distribution of House Values')
plt.show()

"""Split the Dataset"""

# Define features (X) and target (y) (as in original code)
X = data.drop(['median_house_value'], axis=1)
y = data['median_house_value']

# Split the data into training and testing sets (test_size=0.2 as in original code)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("Training set shape:", X_train.shape)
print("Testing set shape:", X_test.shape)

"""Feature Scaling"""

# Initialize the scaler
scaler = StandardScaler()

# Fit and transform the training data
X_train_scaled = scaler.fit_transform(X_train)

# Transform the test data
X_test_scaled = scaler.transform(X_test)

"""Model Training and Evaluation

Linear Regression
"""

# Initialize and train the Linear Regression model
lr_model = LinearRegression()
lr_model.fit(X_train_scaled, y_train)

# Predict on training and test sets
y_pred_lr_train = lr_model.predict(X_train_scaled)
y_pred_lr_test = lr_model.predict(X_test_scaled)

# Calculate R² and RMSE for training and test sets
lr_r2_train = r2_score(y_train, y_pred_lr_train)
lr_r2_test = r2_score(y_test, y_pred_lr_test)
lr_rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_lr_train))
lr_rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_lr_test))

print("Linear Regression Results:")
print(f"Training R² Score: {lr_r2_train:.4f} ({lr_r2_train * 100:.1f}%)")
print(f"Testing R² Score: {lr_r2_test:.4f} ({lr_r2_test * 100:.1f}%)")
print(f"Training RMSE: {lr_rmse_train:.2f}")
print(f"Testing RMSE: {lr_rmse_test:.2f}")

"""Random Forest Regressor"""

# Initialize and train the Random Forest model
rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(X_train_scaled, y_train)

# Predict on training and test sets
y_pred_rf_train = rf_model.predict(X_train_scaled)
y_pred_rf_test = rf_model.predict(X_test_scaled)

# Calculate R² and RMSE for training and test sets
rf_r2_train = r2_score(y_train, y_pred_rf_train)
rf_r2_test = r2_score(y_test, y_pred_rf_test)
rf_rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_rf_train))
rf_rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_rf_test))

print("Random Forest Results:")
print(f"Training R² Score: {rf_r2_train:.4f} ({rf_r2_train * 100:.1f}%)")
print(f"Testing R² Score: {rf_r2_test:.4f} ({rf_r2_test * 100:.1f}%)")
print(f"Training RMSE: {rf_rmse_train:.2f}")
print(f"Testing RMSE: {rf_rmse_test:.2f}")

"""Hyperparameter Tuning for Random Forest"""

# Define parameter grid (as in original code)
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 4, 8],
    'min_samples_split': [2, 4]
}

# Initialize GridSearchCV (using neg_mean_squared_error as in original code)
grid_search = GridSearchCV(
    estimator=RandomForestRegressor(random_state=42),
    param_grid=param_grid,
    cv=5,
    scoring='neg_mean_squared_error',
    return_train_score=True,
    n_jobs=-1
)

# Fit the grid search
grid_search.fit(X_train_scaled, y_train)

# Get the best model
best_rf_model = grid_search.best_estimator_

# Predict on training and test sets
y_pred_best_rf_train = best_rf_model.predict(X_train_scaled)
y_pred_best_rf_test = best_rf_model.predict(X_test_scaled)

# Calculate R² and RMSE for training and test sets
best_rf_r2_train = r2_score(y_train, y_pred_best_rf_train)
best_rf_r2_test = r2_score(y_test, y_pred_best_rf_test)
best_rf_rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_best_rf_train))
best_rf_rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_best_rf_test))

print("Tuned Random Forest Results:")
print(f"Best Parameters: {grid_search.best_params_}")
print(f"Training R² Score: {best_rf_r2_train:.4f} ({best_rf_r2_train * 100:.1f}%)")
print(f"Testing R² Score: {best_rf_r2_test:.4f} ({best_rf_r2_test * 100:.1f}%)")
print(f"Training RMSE: {best_rf_rmse_train:.2f}")
print(f"Testing RMSE: {best_rf_rmse_test:.2f}")

"""Model Comparison"""

# Summarize results
results = pd.DataFrame({
    'Model': ['Linear Regression', 'Random Forest', 'Tuned Random Forest'],
    'Training R² (%)': [lr_r2_train * 100, rf_r2_train * 100, best_rf_r2_train * 100],
    'Testing R² (%)': [lr_r2_test * 100, rf_r2_test * 100, best_rf_r2_test * 100],
    'Training RMSE': [lr_rmse_train, rf_rmse_train, best_rf_rmse_train],
    'Testing RMSE': [lr_rmse_test, rf_rmse_test, best_rf_rmse_test]
})

print("\nModel Comparison:")
display(results.round(2))

# Visualize predictions vs actual values for the best model
plt.figure(figsize=(10, 6))
plt.scatter(y_test, y_pred_best_rf_test, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
plt.xlabel('Actual Median House Value')
plt.ylabel('Predicted Median House Value')
plt.title('Tuned Random Forest: Actual vs Predicted')
plt.show()

